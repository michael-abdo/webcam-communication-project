- Cognitive Overload Detection Implementation Plan
  - Phase 1: Setup & Basic Processing (Day 1)
    - Step 1.1: Environment Setup
      - Create cognitive_overload/ folder structure
      - Install dependencies: pip install mediapipe opencv-python numpy
      - Create requirements.txt
      - Validation: Can import MediaPipe without errors?
    - Step 1.2: Basic Video Input
      - Create video_processor.py that reads one video file
      - Extract frames using OpenCV
      - Validation: Can we successfully read frames from a test video?
    - Step 1.3: Facial Landmark Extraction
      - Initialize MediaPipe Face Mesh
      - Extract 468 landmarks per frame
      - Save raw landmarks to JSON
      - Validation: Do landmarks track face correctly in test video?
  - Phase 2: Overload Indicators (Day 2)
    - Step 2.1: Brow Furrow Detection
      - Calculate distance between eyebrow landmarks (points 70, 63, 105, 66)
      - Track changes over time
      - Validation: Does distance decrease during obvious strain moments?
    - Step 2.2: Eye Strain Indicators
      - Calculate eyelid openness (points 159, 145 for each eye)
      - Track blink rate and squinting
      - Validation: Do values change during focused/strained periods?
    - Step 2.3: Mouth Tension
      - Calculate lip compression (points 13, 14, 15, 16, 17, 18)
      - Detect jaw clenching patterns
      - Validation: Does tension increase during cognitive load?
  - Phase 3: Detection Logic (Day 3)
    - Step 3.1: Threshold Determination
      - Combine indicators into overload score formula
      - Test with obvious high/low cognitive load videos
      - Validation: Does score correlate with expected cognitive state?
    - Step 3.2: Temporal Smoothing
      - Add time-based filtering to reduce noise
      - Validation: Are false positives reduced?
  - Phase 4: UI Integration (Day 4)
    - Step 4.1: Data Bridge
      - Modify existing analysis.html to load JSON files
      - Replace simulated emotion data with overload scores
      - Validation: Does UI display real data correctly?
    - Step 4.2: Visual Indicators
      - Show overload status in video overlay
      - Update metrics panel with overload percentage
      - Validation: Can user clearly see when overload is detected?
  - Phase 5: End-to-End Validation (Day 5)
    - Step 5.1: Multiple Video Testing
      - Process 3-5 different test videos
      - Document accuracy and edge cases
      - Validation: Does system work reliably across different videos?
    - Step 5.2: Performance Optimization
      - Optimize processing speed if needed
      - Reduce memory usage for large videos
      - Validation: Can process videos efficiently?
    - Step 5.3: Error Handling
      - Add robust error handling for edge cases
      - Handle videos with no faces detected
      - Validation: Does system fail gracefully?
  - Architecture Decisions Made
    - Separation of Concerns: Keep existing demo untouched, build in cognitive_overload/
    - File-First Approach: Process video files before live streams
    - Incremental Integration: Standalone Python processing then UI integration
    - Threshold-Based Detection: Simple geometric analysis before ML complexity
  - Key Files to Create
    - cognitive_overload/processing/video_processor.py
    - cognitive_overload/processing/overload_detection.py
    - cognitive_overload/data/input_videos/ (folder)
    - cognitive_overload/data/processed_results/ (folder)
    - cognitive_overload/integration/enhanced_analysis.html
    - cognitive_overload/tests/test_videos/ (folder)
    - requirements.txt
  - Integration Points with Existing UI
    - analysis.html lines 589-631: Video grid with emotion overlays
    - analysis.html lines 644-701: Real-time metrics panel
    - analysis.html lines 704-738: AI insights display
    - index.html lines 516-560: Dashboard metric cards
  - Validation Checkpoints
    - Can extract facial landmarks from video files?
    - Do overload indicators correlate with visible cognitive strain?
    - Does UI integration display real data without breaking existing functionality?
    - Does end-to-end system work reliably across different test videos?